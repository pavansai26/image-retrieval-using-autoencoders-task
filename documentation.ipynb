{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "documentation.ipynb",
      "provenance": [],
      "private_outputs": true,
      "authorship_tag": "ABX9TyNJrxh1JfuI67pgB/CJ77nQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pavansai26/image-retrieval-using-autoencoders-task/blob/master/documentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CAe_x1qCsoJL",
        "colab_type": "text"
      },
      "source": [
        "# step1: importing the necessary libraries\n",
        "\n",
        "1)I am using tensorflow library for implementation of autoencoders\n",
        "\n",
        "2)filtering the warnings\n",
        "\n",
        "# step2:\n",
        "\n",
        "1)getting the data from google drive and accessing the google drive\n",
        "\n",
        "# step3:\n",
        "\n",
        "1)shuffling the data to avoid overfitting\n",
        "\n",
        "2)splitting the data for training and testing\n",
        "\n",
        "# step4:\n",
        "\n",
        "1)resizing the data and normalizing the data by 255\n",
        "for converting the data into int8 format\n",
        "\n",
        "# step5:\n",
        "\n",
        "1)model training using sequential method in this i am using relu activationto reduce the vanishing gradient problem\n",
        "\n",
        "2)In this model i am using adam optimizer and binary_crossentropy loss function\n",
        "\n",
        "# step6:\n",
        "\n",
        "1)printing the model summary for understanding  the model\n",
        "\n",
        "# step7:\n",
        "\n",
        "1)visualizing the model for how the data pass into the different layers\n",
        "\n",
        "# step8:\n",
        "\n",
        "1)our data has high dimensions to visualize high dimensional data umap is so useful so for this reason i am using UMAP\n",
        "\n",
        "# step9:\n",
        "\n",
        "1)clustering the similar images using kmeans clustering\n",
        "\n",
        "# step10:\n",
        "\n",
        "1)visualization of cluster data\n",
        "\n",
        "step11:\n",
        "\n",
        "1)fitting the data\n",
        "\n",
        "# step12:\n",
        "\n",
        "1)visualizing the loss\n",
        "\n",
        "# step13:\n",
        "\n",
        "1)finding the distance between images uisng cosine distance for finding the similar images\n",
        "\n",
        "## step14:\n",
        "\n",
        "1)visualizing the similar images\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Js-eMxnVwyHK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}